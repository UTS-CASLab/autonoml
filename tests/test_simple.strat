Strategy:
  Do HPO: y
  Do Random: y
Optimiser:
  BOHB:
    Note: Prior to HPO, the dataset is randomly split into a training fraction and
      a validation fraction. For i iterations and p partitions, BOHB seeks to sample
      p^i models on 1/p^i of training data at the 1st iteration, then propagate the
      best 1/p models to the next iteration.
    Iterations: 3
    Partitions: 2
    Validation Fraction: 0.25
Search Space:
  OnlineLinearRegressor:
    Include: y
    Hpars:
      batch_size:
        Vary: y
        Default: 1
        Min: 1
        Max: 1000
      learning_rate:
        Vary: y
        Default: 0.001
        Min: 1.0e-06
        Max: 1.0
  DummyRegressor:
    Include: y
  LinearRegressor:
    Include: y
  LinearSupportVectorRegressor:
    Include: y
  PartialLeastSquaresRegressor:
    Include: y
